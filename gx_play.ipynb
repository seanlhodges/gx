{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Assessment\n",
    "\n",
    "#### Expectations\n",
    "\n",
    "To assess data quality, expectations for quality need to be defined and agreed with subject matter experts. \n",
    "\n",
    "With expectations set, these can be expressed as rules that data can be measured against. For example, a table needs to have the fields we are expecting, and of the right type; fields values may need to be unique, or may need to conform to a given domain of values. \n",
    "\n",
    "Whatever the expectations, they will require checking on a regular basis to ensure data quality is being maintained, or to identify where problems might be occurring. \n",
    "\n",
    "It would also be really handy to have some sort of documentation generated that we could keep along with our data to demonstrate what was assessed, how the data performed, and whether any additional rules might be needed.\n",
    "\n",
    "The *great_expectations* library provides tools to assist.\n",
    "\n",
    "To get started, and in a cloned environment, use pip to install:\n",
    "\n",
    "``` shell\n",
    "pip install great-expectations\n",
    "```\n",
    "\n",
    "To verify, using python in your cloned environment, run:\n",
    "\n",
    "``` python\n",
    "import great_expectations as gx\n",
    "print(gx.__version__)\n",
    "```\n",
    "This returns the current version of great-expectations - 1.3.0 (as at 1 Janaury 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this example is taken from [Introduction to GX Core](https://docs.greatexpectations.io/docs/core/introduction/).\n",
    "\n",
    "To get started, import the library and create a context (which acts as a container for the workspace you are going to build to do the data quality meauring thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "context = gx.get_context()\n",
    "# assert type(context).__name__ == \"EphemeralDataContext\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuration\n",
    "\n",
    "There is a lot of configuration that needs to be done to set up the context so that you can run your data against a set of rules.\n",
    "\n",
    "The first thing is to set up references to the data. Pandas dataframes are a recognised source of data, as are SQL databases, or cloud-based systems. For this exercise, we'll just use a pandas dataframe to keep things simple. In the future it would be useful to pair this against data stored in our MS SQL databases (imagine this against IRIS, LAB, etc).\n",
    "\n",
    "Anyway, as far as I can tell, the initial config is structured like this:\n",
    "```\n",
    "    context                                      Workspace\n",
    "       |-- data_source                           Source system = Pandas, SQL, Cloud ...\n",
    "              |-- data_asset                     Data container = Dataframe, Table, ....\n",
    "                     |-- batch_definition        Defining where data is coming from and any filters if needed\n",
    " ```\n",
    "\n",
    " These things are all defined as a skeleton to start with, and then updated as needed. Boiler-plate code, in other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all taken from the documentation\n",
    "\n",
    "# SETUP FOR THE EXAMPLE:\n",
    "data_source = context.data_sources.add_pandas(name=\"my_data_source\")\n",
    "data_asset = data_source.add_dataframe_asset(name=\"my_dataframe_data_asset\")\n",
    "\n",
    "# Retrieve the Data Asset\n",
    "data_source_name = \"my_data_source\"\n",
    "data_asset_name = \"my_dataframe_data_asset\"\n",
    "data_asset = context.data_sources.get(data_source_name).get_asset(data_asset_name)\n",
    "\n",
    "# Define the Batch Definition name\n",
    "batch_definition_name = \"my_batch_definition\"\n",
    "\n",
    "# Add a Batch Definition to the Data Asset\n",
    "batch_definition = data_asset.add_batch_definition_whole_dataframe(\n",
    "    batch_definition_name\n",
    ")\n",
    "assert batch_definition.name == batch_definition_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we bring in pandas and create a dataframe, and create a variable called 'batch_parameters' that contains a dictionary of {\"dataframe\": dataframe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we actually bring in some data ... \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"~/gx/MyEBirdData-83.csv\"\n",
    "dataframe = pd.read_csv(csv_path)\n",
    "\n",
    "# ... and this can get added into the context above through \"batch_parameters\"\n",
    "batch_parameters = {\"dataframe\": dataframe}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add the batch_parameters to the empty batch_definition object created previously. The data gets referenced in our context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataframe as a Batch\n",
    "batch = batch_definition.get_batch(batch_parameters=batch_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up expectations to validate\n",
    "\n",
    "The next step is to build the data quality busines rules, or expectations, to be assessed. \n",
    "\n",
    "A lot of rules come prebuilt with the great-expectation library (see https://greatexpectations.io/expectations/). The available list is reproduced in the dataframe below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expectation</th>\n",
       "      <th>Data quality issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExpectColumnProportionOfUniqueValuesToBeBetween</td>\n",
       "      <td>Cardinality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExpectColumnUniqueValueCountToBeBetween</td>\n",
       "      <td>Cardinality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ExpectColumnValuesToBeUnique</td>\n",
       "      <td>Cardinality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ExpectCompoundColumnsToBeUnique</td>\n",
       "      <td>Cardinality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ExpectSelectColumnValuesToBeUniqueWithinRecord</td>\n",
       "      <td>Cardinality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExpectColumnPairValuesToBeEqual</td>\n",
       "      <td>Data Integrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ExpectMulticolumnSumToEqual</td>\n",
       "      <td>Data Integrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExpectColumnKLDivergenceToBeLessThan</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExpectColumnPairValuesAToBeGreaterThanB</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ExpectColumnStdevToBeBetween</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ExpectColumnSumToBeBetween</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExpectColumnValueZScoresToBeLessThan</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ExpectColumnValuesToBeBetween</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ExpectColumnValuesToBeNull</td>\n",
       "      <td>Missingness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ExpectColumnValuesToNotBeNull</td>\n",
       "      <td>Missingness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExpectColumnMaxToBeBetween</td>\n",
       "      <td>Numerical data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExpectColumnMeanToBeBetween</td>\n",
       "      <td>Numerical data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExpectColumnMedianToBeBetween</td>\n",
       "      <td>Numerical data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExpectColumnMinToBeBetween</td>\n",
       "      <td>Numerical data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ExpectColumnQuantileValuesToBeBetween</td>\n",
       "      <td>Numerical data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExpectColumnValueLengthsToBeBetween</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExpectColumnValueLengthsToEqual</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ExpectColumnValuesToMatchLikePattern</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ExpectColumnValuesToMatchLikePatternList</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ExpectColumnValuesToMatchRegex</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ExpectColumnValuesToMatchRegexList</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ExpectColumnValuesToNotMatchLikePattern</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ExpectColumnValuesToNotMatchLikePatternList</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ExpectColumnValuesToNotMatchRegex</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ExpectColumnValuesToNotMatchRegexList</td>\n",
       "      <td>Pattern matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExpectColumnToExist</td>\n",
       "      <td>Schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExpectColumnValuesToBeInTypeList</td>\n",
       "      <td>Schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ExpectColumnValuesToBeOfType</td>\n",
       "      <td>Schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ExpectTableColumnCountToBeBetween</td>\n",
       "      <td>Schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ExpectTableColumnCountToEqual</td>\n",
       "      <td>Schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ExpectTableColumnsToMatchOrderedList</td>\n",
       "      <td>Schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ExpectTableColumnsToMatchSet</td>\n",
       "      <td>Schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExpectColumnDistinctValuesToBeInSet</td>\n",
       "      <td>Sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExpectColumnDistinctValuesToContainSet</td>\n",
       "      <td>Sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExpectColumnDistinctValuesToEqualSet</td>\n",
       "      <td>Sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExpectColumnMostCommonValueToBeInSet</td>\n",
       "      <td>Sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExpectColumnPairValuesToBeInSet</td>\n",
       "      <td>Sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ExpectColumnValuesToBeInSet</td>\n",
       "      <td>Sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ExpectColumnValuesToNotBeInSet</td>\n",
       "      <td>Sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ExpectTableRowCountToBeBetween</td>\n",
       "      <td>Volume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ExpectTableRowCountToEqual</td>\n",
       "      <td>Volume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ExpectTableRowCountToEqualOtherTable</td>\n",
       "      <td>Volume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Expectation Data quality issue\n",
       "12  ExpectColumnProportionOfUniqueValuesToBeBetween        Cardinality\n",
       "17          ExpectColumnUniqueValueCountToBeBetween        Cardinality\n",
       "26                     ExpectColumnValuesToBeUnique        Cardinality\n",
       "37                  ExpectCompoundColumnsToBeUnique        Cardinality\n",
       "39   ExpectSelectColumnValuesToBeUniqueWithinRecord        Cardinality\n",
       "10                  ExpectColumnPairValuesToBeEqual     Data Integrity\n",
       "38                      ExpectMulticolumnSumToEqual     Data Integrity\n",
       "3              ExpectColumnKLDivergenceToBeLessThan       Distribution\n",
       "9           ExpectColumnPairValuesAToBeGreaterThanB       Distribution\n",
       "14                     ExpectColumnStdevToBeBetween       Distribution\n",
       "15                       ExpectColumnSumToBeBetween       Distribution\n",
       "20             ExpectColumnValueZScoresToBeLessThan       Distribution\n",
       "21                    ExpectColumnValuesToBeBetween       Distribution\n",
       "24                       ExpectColumnValuesToBeNull        Missingness\n",
       "32                    ExpectColumnValuesToNotBeNull        Missingness\n",
       "4                        ExpectColumnMaxToBeBetween     Numerical data\n",
       "5                       ExpectColumnMeanToBeBetween     Numerical data\n",
       "6                     ExpectColumnMedianToBeBetween     Numerical data\n",
       "7                        ExpectColumnMinToBeBetween     Numerical data\n",
       "13            ExpectColumnQuantileValuesToBeBetween     Numerical data\n",
       "18              ExpectColumnValueLengthsToBeBetween   Pattern matching\n",
       "19                  ExpectColumnValueLengthsToEqual   Pattern matching\n",
       "27             ExpectColumnValuesToMatchLikePattern   Pattern matching\n",
       "28         ExpectColumnValuesToMatchLikePatternList   Pattern matching\n",
       "29                   ExpectColumnValuesToMatchRegex   Pattern matching\n",
       "30               ExpectColumnValuesToMatchRegexList   Pattern matching\n",
       "33          ExpectColumnValuesToNotMatchLikePattern   Pattern matching\n",
       "34      ExpectColumnValuesToNotMatchLikePatternList   Pattern matching\n",
       "35                ExpectColumnValuesToNotMatchRegex   Pattern matching\n",
       "36            ExpectColumnValuesToNotMatchRegexList   Pattern matching\n",
       "16                              ExpectColumnToExist             Schema\n",
       "23                 ExpectColumnValuesToBeInTypeList             Schema\n",
       "25                     ExpectColumnValuesToBeOfType             Schema\n",
       "40                ExpectTableColumnCountToBeBetween             Schema\n",
       "41                    ExpectTableColumnCountToEqual             Schema\n",
       "42             ExpectTableColumnsToMatchOrderedList             Schema\n",
       "43                     ExpectTableColumnsToMatchSet             Schema\n",
       "0               ExpectColumnDistinctValuesToBeInSet               Sets\n",
       "1            ExpectColumnDistinctValuesToContainSet               Sets\n",
       "2              ExpectColumnDistinctValuesToEqualSet               Sets\n",
       "8              ExpectColumnMostCommonValueToBeInSet               Sets\n",
       "11                  ExpectColumnPairValuesToBeInSet               Sets\n",
       "22                      ExpectColumnValuesToBeInSet               Sets\n",
       "31                   ExpectColumnValuesToNotBeInSet               Sets\n",
       "44                   ExpectTableRowCountToBeBetween             Volume\n",
       "45                       ExpectTableRowCountToEqual             Volume\n",
       "46             ExpectTableRowCountToEqualOtherTable             Volume"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"~/gx/gx_expectation_list.csv\"\n",
    "rules = pd.read_csv(csv_path)\n",
    "rules.sort_values([\"Data quality issue\",\"Expectation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help build the rules, doing some data prep to populate the expectations later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Submission ID': dtype('O'), 'Common Name': dtype('O'), 'Scientific Name': dtype('O'), 'Taxonomic Order': dtype('int64'), 'Count': dtype('int64'), 'State/Province': dtype('O'), 'County': dtype('O'), 'Location ID': dtype('O'), 'Location': dtype('O'), 'Latitude': dtype('float64'), 'Longitude': dtype('float64'), 'Date': dtype('O'), 'Time': dtype('O'), 'Protocol': dtype('O'), 'Duration (Min)': dtype('float64'), 'All Obs Reported': dtype('int64'), 'Distance Traveled (km)': dtype('float64'), 'Area Covered (ha)': dtype('float64'), 'Number of Observers': dtype('int64'), 'Breeding Code': dtype('O'), 'Observation Details': dtype('O'), 'Checklist Comments': dtype('O'), 'ML Catalog Numbers': dtype('O')}\n"
     ]
    }
   ],
   "source": [
    "# To help build the rules, doing some data prep to populate the expectations later\n",
    "# Building dictionary of data types\n",
    "\n",
    "# Getting data types to validate data columns\n",
    "d={}\n",
    "s = dataframe.dtypes\n",
    "\n",
    "d = s.to_dict(into=d)\n",
    "print(d)\n",
    "\n",
    "# Tidying up dictionary values  to string equivalents, and replacing 'object' with 'str'\n",
    "for key, value in d.items():\n",
    "    if str(value)=='object':\n",
    "        d[key]='str'\n",
    "    else:\n",
    "        d[key]=str(value)\n",
    "#print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the context ready, we can now create a series of data quality tests, \n",
    "# or expectations.\n",
    "# Usually, there will be many tests to define, and these are grouped into a \"suite\"\n",
    "\n",
    "# Setup increment number for expectation suite, validation definition, and checkpoint names\n",
    "import uuid\n",
    "label_number =str(uuid.uuid4())\n",
    "\n",
    "# Create an Expectation Suite\n",
    "suite_name = \"suite-\"+label_number\n",
    "suite = gx.ExpectationSuite(name=suite_name)\n",
    "\n",
    "# Add the Expectation Suite to the Data Context\n",
    "suite = context.suites.add(suite)\n",
    "\n",
    "# Create an Expectation to put into an Expectation Suite\n",
    "# expectation = gx.expectations.ExpectColumnValuesToNotBeNull(column=\"passenger_count\")\n",
    "# SCHEMA CHECK\n",
    "#   1. ExpectTableColumnsToMatchSet()\n",
    "#   First verify the columns - all columns must exist. \n",
    "#   If any additional columns are found this will cause test to return False.\n",
    "#   Set exact_match=False if additional columns are ok.\n",
    "expectation = gx.expectations.ExpectTableColumnsToMatchSet(column_set=list(dataframe.columns),\n",
    "                                                           exact_match=True)\n",
    "# Add the previously created Expectation to the Expectation Suite\n",
    "suite.add_expectation(expectation)\n",
    "\n",
    "# SCHEMA CHECK\n",
    "#   2.  ExpectTableColumnsToMatchOrderedList()\n",
    "expectation = gx.expectations.ExpectTableColumnsToMatchOrderedList(column_list=list(dataframe.columns))\n",
    "suite.add_expectation(expectation)\n",
    "\n",
    "# SCHEMA CHECK\n",
    "#   3. ExpectTableColumnCountToEqual\n",
    "expectation = gx.expectations.ExpectTableColumnCountToEqual(value=len(dataframe.columns))\n",
    "suite.add_expectation(expectation)\n",
    "\n",
    "# SCHEMA CHECK\n",
    "#   4. ExpectColumnValuesToBeOfType\n",
    "#   This needs to be specified for each column.\n",
    "\n",
    "for key, value in d.items():\n",
    "    expectation = gx.expectations.ExpectColumnValuesToBeOfType(column=key, type_=value)\n",
    "    suite.add_expectation(expectation)\n",
    "                                                     \n",
    "# Add another Expectation to the Expectation Suite.\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Count\")\n",
    ")\n",
    "\n",
    "# Update the configuration of an Expectation, then push the changes to the Expectation Suite\n",
    "#expectation.column = \"pickup_location_id\"\n",
    "#expectation.save()\n",
    "\n",
    "# Retrieve an Expectation Suite from the Data Context\n",
    "existing_suite_name = (\n",
    "    suite_name  # replace this with the name of your Expectation Suite\n",
    ")\n",
    "suite = context.suites.get(name=existing_suite_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_definition_name = \"vdef-\"+label_number\n",
    "validation_definition = gx.ValidationDefinition(\n",
    "    data=batch_definition, suite=suite, name=validation_definition_name\n",
    ")\n",
    "validation_definition = context.validation_definitions.add(validation_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Checkpoint(name='checkpoint-bbf6c121-b2a7-4862-9993-d37a1a63a026', validation_definitions=[ValidationDefinition(name='vdef-bbf6c121-b2a7-4862-9993-d37a1a63a026', data=BatchDefinition(id=UUID('f228709f-4fb5-4187-ba49-519f18e10820'), name='my_batch_definition', partitioner=None), suite={\n",
       "  \"name\": \"suite-bbf6c121-b2a7-4862-9993-d37a1a63a026\",\n",
       "  \"id\": \"8cda8384-be75-4ad6-acb7-e4e06b15edd4\",\n",
       "  \"expectations\": [\n",
       "    {\n",
       "      \"type\": \"expect_table_columns_to_match_set\",\n",
       "      \"kwargs\": {\n",
       "        \"column_set\": [\n",
       "          \"Submission ID\",\n",
       "          \"Common Name\",\n",
       "          \"Scientific Name\",\n",
       "          \"Taxonomic Order\",\n",
       "          \"Count\",\n",
       "          \"State/Province\",\n",
       "          \"County\",\n",
       "          \"Location ID\",\n",
       "          \"Location\",\n",
       "          \"Latitude\",\n",
       "          \"Longitude\",\n",
       "          \"Date\",\n",
       "          \"Time\",\n",
       "          \"Protocol\",\n",
       "          \"Duration (Min)\",\n",
       "          \"All Obs Reported\",\n",
       "          \"Distance Traveled (km)\",\n",
       "          \"Area Covered (ha)\",\n",
       "          \"Number of Observers\",\n",
       "          \"Breeding Code\",\n",
       "          \"Observation Details\",\n",
       "          \"Checklist Comments\",\n",
       "          \"ML Catalog Numbers\"\n",
       "        ]\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"1d50da81-0232-4b6a-9c35-0ea6f346e4b0\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_table_columns_to_match_ordered_list\",\n",
       "      \"kwargs\": {\n",
       "        \"column_list\": [\n",
       "          \"Submission ID\",\n",
       "          \"Common Name\",\n",
       "          \"Scientific Name\",\n",
       "          \"Taxonomic Order\",\n",
       "          \"Count\",\n",
       "          \"State/Province\",\n",
       "          \"County\",\n",
       "          \"Location ID\",\n",
       "          \"Location\",\n",
       "          \"Latitude\",\n",
       "          \"Longitude\",\n",
       "          \"Date\",\n",
       "          \"Time\",\n",
       "          \"Protocol\",\n",
       "          \"Duration (Min)\",\n",
       "          \"All Obs Reported\",\n",
       "          \"Distance Traveled (km)\",\n",
       "          \"Area Covered (ha)\",\n",
       "          \"Number of Observers\",\n",
       "          \"Breeding Code\",\n",
       "          \"Observation Details\",\n",
       "          \"Checklist Comments\",\n",
       "          \"ML Catalog Numbers\"\n",
       "        ]\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"e74f68e5-709d-4b31-9172-3ef8a7d82898\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_table_column_count_to_equal\",\n",
       "      \"kwargs\": {\n",
       "        \"value\": 23\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"33b10713-a7e4-4456-86c6-9bc27a7b0649\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Submission ID\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"31926dd3-48f5-4eb1-81ca-4dcbf0a7e1d7\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Common Name\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"0e1bbd50-1f28-4732-a9d8-ab1bb9c8e32f\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Scientific Name\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"618560be-3f32-488d-9d39-be995d97cc3e\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Taxonomic Order\",\n",
       "        \"type_\": \"int64\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"b170eebe-8f26-419b-89ea-1fba864e98af\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Count\",\n",
       "        \"type_\": \"int64\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"fd6dfb7c-67e3-4c21-aab4-757b4cf706c3\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"State/Province\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"b5da2262-a9c2-4888-bdac-20b2728a3894\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"County\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"bc80a658-426f-4e17-b63d-efa125d209f4\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Location ID\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"f9a75b75-0d36-4ef6-9bb7-12df33139d17\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Location\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"d22713ad-d2b5-48b5-8a72-fd3f9ee2b156\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Latitude\",\n",
       "        \"type_\": \"float64\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"ae1daeb0-45f0-4c4c-9a7e-e8ec884cf893\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Longitude\",\n",
       "        \"type_\": \"float64\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"740207b7-b524-4f0e-bc13-c871fb8a9d65\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Date\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"7a7a0ff7-21e8-4f6b-83b9-e939d0d5a969\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Time\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"f995cf8d-5973-4059-8040-bde08e0dbd18\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Protocol\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"1e8a8480-5102-476b-aa28-2229e9f658c1\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Duration (Min)\",\n",
       "        \"type_\": \"float64\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"ca3e0a9d-f4c4-4b44-8043-55e2d7417252\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"All Obs Reported\",\n",
       "        \"type_\": \"int64\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"1d475997-a55a-496c-9835-a2010baae213\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Distance Traveled (km)\",\n",
       "        \"type_\": \"float64\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"f32bbe9d-87b7-43b7-9c29-ba5c7224de25\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Area Covered (ha)\",\n",
       "        \"type_\": \"float64\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"5178771c-1423-4af0-b798-9be95364f9b2\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Number of Observers\",\n",
       "        \"type_\": \"int64\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"da9c4d74-96fa-4d86-8ee8-3a31872a62ae\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Breeding Code\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"18accc2f-e6ff-424c-b63d-1254b48e799e\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Observation Details\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"8e21202f-c642-4252-9949-70dd77c8fcd3\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Checklist Comments\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"0ff4b08c-fafe-43f1-b340-9d14dbbdae29\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"ML Catalog Numbers\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"d0ec1924-7c5d-4f5e-93c3-b84ab30b6502\"\n",
       "    },\n",
       "    {\n",
       "      \"type\": \"expect_column_values_to_not_be_null\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Count\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"id\": \"6b48e37e-43bf-4168-bb60-24151106abdb\"\n",
       "    }\n",
       "  ],\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"1.3.0\"\n",
       "  },\n",
       "  \"notes\": null\n",
       "}, id='bc72dae0-db7a-4b30-89e3-e7c72d362a28')], actions=[UpdateDataDocsAction(type='update_data_docs', name='update_all_data_docs', site_names=[])], result_format={'result_format': 'COMPLETE'}, id='492510ed-e147-41b7-891e-c2df48d3468e')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from great_expectations.checkpoint import (\n",
    "    UpdateDataDocsAction,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a list of one or more Validation Definitions for the Checkpoint to run\n",
    "validation_definitions = [\n",
    "    context.validation_definitions.get(validation_definition_name)\n",
    "]\n",
    "\n",
    "# Create a list of Actions for the Checkpoint to perform\n",
    "action_list = [\n",
    "    # This Action updates the Data Docs static website with the Validation\n",
    "    #   Results after the Checkpoint is run.\n",
    "    UpdateDataDocsAction(\n",
    "        name=\"update_all_data_docs\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create the Checkpoint\n",
    "checkpoint_name = \"checkpoint-\"+label_number\n",
    "checkpoint = gx.Checkpoint(\n",
    "    name=checkpoint_name,\n",
    "    validation_definitions=validation_definitions,\n",
    "    actions=action_list,\n",
    "    result_format={\"result_format\": \"COMPLETE\"},\n",
    ")\n",
    "\n",
    "# Save the Checkpoint to the Data Context\n",
    "context.checkpoints.add(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a81f3d418a43948c49f8089f8266d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the checkpoint\n",
    "\n",
    "checkpoint = context.checkpoints.get(checkpoint_name)\n",
    "\n",
    "#batch_parameters = {\"month\": \"01\", \"year\": \"2019\"}\n",
    "\n",
    "#expectation_parameters = {\n",
    "#    \"expect_fare_max_to_be_above\": 5.00,\n",
    "#    \"expect_fare_max_to_be_below\": 1000.00,\n",
    "#}\n",
    "\n",
    "validation_results = checkpoint.run(\n",
    "    batch_parameters=batch_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.build_data_docs()\n",
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the expectation suite to validate against another dataset\n",
    "\n",
    "This is where the value of setting up everything above comes into its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7301f6d1e5b64ba6af4c38aee6433a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "csv_path = \"~/gx/MyEBirdData-100.csv\"\n",
    "dataframe = pandas.read_csv(csv_path)\n",
    "\n",
    "# ... and this can get added into the context above through \"batch_parameters\"\n",
    "batch_parameters = {\"dataframe\": dataframe}\n",
    "# Get the dataframe as a Batch\n",
    "#batch = batch_definition.get_batch(batch_parameters=batch_parameters)\n",
    "\n",
    "# Adding another checkpoint\n",
    "validation_results = checkpoint.run(\n",
    "    batch_parameters=batch_parameters\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix\n",
    "\n",
    "##### Common Data Quality Dimensions\n",
    "\n",
    "Citation: \n",
    "\n",
    "*Dama International. 2024. DAMA-DMBOK: Data Management Body of Knowledge (2nd Edition, Revised). Technics Publications, LLC, Basking Ridge, NJ, USA.*\n",
    "\n",
    "**Note: other definitions of data quality dimensions exist. What's listed below is a set where there is general agreement.**\n",
    "\n",
    "Table 29 from DAMA-DMBOK\n",
    "\n",
    "\n",
    "|Dimension of Quality|Description|\n",
    "|---|---|\n",
    "|Validity|Validity refers to whether data values are consistent within a defined domain of values|\n",
    "|Completeness|Completeness refers to whether all the required data is present. For example, are all the mandatory components of an address populated?. Completeness can be measured at the column, record, or data set level.|\n",
    "|Consistency|Consistency is ensuring that data values are coded using the same approach, assessment and valuation criteria. Consistency is between two different data items, potentially within a data set and between data sets, and across time. Consistency may be defined between one set of data element values and another data element set within the same record (record-level consistency), between one set of data element values and another data element set in differet records (cross-record consistency), or between one set of data element values and the same data element set within the same record at different points in time (temporal consistency). Consistency can also be used  to refer to consistency of format. Take care not to confuse consistency with accuracy or correctness.\n",
    "|Integrity|Integrity refers to the lack of incoherent values and broken relationships in data. Data sets without integrity are seen as corrupted or have data loss. Data sets without referential integrity have 'orphans' - invalid reference keys, or 'duplicates' - identical rows which may negatively affect aggregation functions.|\n",
    "|Timeliness|Data Timeliness refers to the time that data needs to become accessible to a user after its capture or update. Timeliness is the expectation and actual delay before the data becomes available.|\n",
    "|Currency|Currency is the date that the data set was last updated relative to now and the likelihood that it is still correct. Different data sets will have diefferent currency expectations from relatively static data to highly volatile data. Static data remains current for a long period. Volatile data remains current for a relatively short period.|\n",
    "|Reasonableness|Reasonableness asks whether a data pattern meets expectations. For example, whether a distribution of sales in a geographic area makes sense based on what is known about the customers in that area. For example, based on previous customer logins at 5pm, are today's customer logins to our systems out of the ordinary?|\n",
    "|Uniqueness / Deduplication|Uniqueness states that no real-world entity exists more than once within the data set. Asserting uniqueness of the entities within a data set implies that each row relate to each entity in the real world, and only that specific entity.|\n",
    "|Accuracy|Accuracy refers to the degree that data correctly represents 'real-life' entities. Accuracy is difficult to measure unless an organisation can reproduce data collection or manually confirm accuracy of records. Most measures of accuracy use the other dimensions to imply accuracy.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Quality Business Rules\n",
    "\n",
    "In management of data quality, one of the goals is to *define and implement processes to measure, monitor, and report on data quality levels*.\n",
    "\n",
    "*Business Rules* describe how data should exist in order to be useful and usable within an organisation. *Data Quality Business Rules* are aligned with data quality dimensions and are used to describe Data Quality Requirements. For example, business rules for managing state/province names could be:\n",
    "\n",
    "- **Validity** - all state/province names must be a value from the reference table stored in the Metadata repository.\n",
    "- **Completeness** - All addresses must have a state/province if the country is divided into states/provinces. Otherwise, they should not have a state/province value.\n",
    "- **Integrity** - All state/province names must have a value that is linked to the country name of the address.\n",
    "- **Currency** - The reference values will be periodically updated and the current addresses will need to be brought up to date with the current names. This will keep all the state/province names current with the latest reference values.\n",
    "  \n",
    "Some common business rule types (aligned with most common dimensions) are:\n",
    "\n",
    "- **Validity**: can be implemented through rules such as:\n",
    "    + **Format compliance rules**: One or more patterns specify values assigned to a data element, such as standards for formatting telephone numbers.\n",
    "    + **Value domain membership**: Specify that a data element's assigned value is included in those enumerated in a defined data value domain, such as 2-character United States Postal Codes for a STATE field\n",
    "    + **Range conformance**: A data element assigned value must be within a defined numeric, lexicographic, or time range, such as greater than 0 and less than 100 for a numeric range.\n",
    "    + **Mapping conformance**: Indicating that the value assigned to a data element must correspond to one selected from a value-domain that maps to other equivalent corresponding value domain(s). The STATE data domain again provides a good example, since State values may be represented using different value domains (USPS Postal Codes, FIPS 2-digit codes, full names), and these types of rules validate that 'AL' and '01' both map to 'Alabama'.\n",
    "  \n",
    "- **Completeness or Value presence and record completeness**: Rules defining the conditions under which missing values are acceptable or unacceptable.\n",
    "\n",
    "- **Consistency rules**: Conditional assertions that refer to maintaining a relationship between two (or more) data elements based on the actual values of those data elements. For example, address validation where postal codes correspond to particular States or Provinces.\n",
    "\n",
    "- **Consistency may also drive Definitional conformance rules**: Confirm that the same understanding of data definitions is implemented and used properly in processes across the organisation. Confirmation includes algorithmic agreement on calculated fields, including any time or local constraints, and rollup and status interdependence rules.\n",
    "\n",
    "- **Integrity rules**: Rules expressed as assertions to maintain a relationship between two (or more) data elements based on the actual values of those data elements. For example, address validation where postal codes correspond to particular States or Provinces. (How does this differ from the *Consistency rule*. I think the integrity rule needs be updated based on the description of Data Quality Dimension - Rules to determine if orphaned records exist between two or more data sets. Duplicates are dealth with under uniqueness.\n",
    "\n",
    "- **Timeliness validation**: Rules that indicate the characteristics associated with expectations for accessibility and availability of data. Timeliness rules often break down a process into a series of stage where timeliness is monitored thrugh the cycle to ensure the dependent data is also achieving the timeliness requirement.\n",
    "\n",
    "- **Uniqueness** Rules that specify which entities must have a unique representation and whether one and only one record exists for each represented real world object. In Data Quality checks, we may habe rules that go beyond simple tests to assess the likelihood of a duplicate value. For example, it may search for people living at the same address that are behaving in a cooperative fashion (that leads us to believe they may be the same person).\n",
    "\n",
    "- **Reasonableness**: May be implemented through aggregating functions applied to sets of data instances. Examples of aggregation checks include validating reasonableness by a:\n",
    "    + *relative* measure. For example, today's record count in a file is assessed by keeping statistics over time to generate an understanding of \"normality\" which is used to assess reasonableness in this particular instance.\n",
    "    + *absolute* measure. For example, validating the reasonableness of an aveerage amount calculated from a set of transactions by a set of fixed thresholds that the values must fall within.\n",
    "\n",
    "  - These concepts of relative and absolute measures for determining reasonability can be used on any data types, such as an absolute date range (fixed period of time), or a relative date range (e.g. to today), computed totals, record counts, etc. \n",
    "\n",
    "- **Accuracy verification**: Compare a data value against a corresponding value in a system of record or other verified source to verify that the values match."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gx130",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
